{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グリッドサーチとは？\n",
    "```\n",
    "グリッドサーチとは、モデルの精度を向上させるために用いられる手法で、全てのパラメータの組み合わせを試してみる方法のことです。\n",
    "イメージとしてはfor分回して、パラメータの組み合わせを全て試してみて最も評価精度の良いものを探索する方法です。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グリッドサーチのメリット・デメリット\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単純なグリッドサーチ\n",
    "```\n",
    "単純なグリッドサーチは、2つのパラメータに対するただのforループで実装することができます。\n",
    "実際に試してみたいと思います。アルゴリズムは分類問題で利用される、SVM(サポートベクターマシン)を用いてみます。\n",
    "実施していることとしてはfor分でSVMのハイパーパラメータである、「gammaとC」を調整しているだけです。\n",
    "```\n",
    "#### ハイパーパラメータとは\n",
    "```\n",
    "機械学習で使われるモデルには多かれ少なかれ分析者が設定しなければならないパラメータがあります。機械学習で学習されない、機械学習の上にある（ハイパーな）パラメータなのでハイパーパラメータと呼ばれます。\n",
    "```\n",
    "\n",
    "#### 処理フロー\n",
    "```\n",
    "1.for list[gamma]\n",
    "2.for list[C]\n",
    "3.create the model\n",
    "4.get model score\n",
    "5.if model score > model score[pre]\n",
    "6.save model score and params\n",
    "7.print best score and params\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mglearn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:112　size of test set:38\n",
      "Best score: 0.97\n",
      "Best parameters: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "print(\"Size of training set:{}　size of test set:{}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        #それぞれのパラメータの組み合わせに足してSVCを訓練\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        #SVCをテストセットで評価\n",
    "        score = svm.score(X_test, y_test)\n",
    "        #良いスコアであればスコアとパラメータを保持\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C':C, 'gamma':gamma}\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "評価制度の最も高くなるパラメータは、gamma: 0.001、C: 100であり、精度は97%と非常に高いスコアを得ることができました。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単純なグリッドサーチの問題点\n",
    "```\n",
    "上記は高い精度が確認できますが大きな問題点があります。上記の方法は、テストデータをパラメータのチューニングで活用してしまいました。パラメータのチューニングで活用したテストデータでモデルの精度を評価することができません。これは訓練データとテストデータを分けた理由と同じで、一度活用したデータで予測を行うこと＝未知のデータに対する予測にはならないからです。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解決方法\n",
    "```\n",
    "この問題を解決する1つの方法は、もう一度分割し、3つのセットにする方法です。各データセットの役割は以下の通りです。\n",
    "\n",
    "・training set:モデルを構築する訓練セット\n",
    "・validation set:モデルのパラメータ選択に用いる検証セット\n",
    "・test set:選択したパラメータの性能を評価するためのテストセット\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAABrCAYAAACbkni7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1094bb4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_threefold_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 処理フロー\n",
    "```\n",
    "1.split and create train , validation, test data\n",
    "2.loop params\n",
    "3.create model by train data\n",
    "4.evaluate model by validation data\n",
    "5.save the high score params\n",
    "6.evaluate model made by high params by test data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train set :84\n",
      "size of validation set:28\n",
      "size of test set:38\n",
      "\n",
      "Best score on validation set:0.96\n",
      "Best parameters: {'C': 10, 'gamma': 0.001}\n",
      "Test set score with best parameters:0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# データを訓練 + 検証セットとテストセットに分割する\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "#訓練+検証セットを訓練セットと検証セットに分割する\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval,y_trainval,random_state=1)\n",
    "print(\"size of train set :{}\\nsize of validation set:{}\\nsize of test set:\"\n",
    "       \"{}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # それぞれのパラメータの組み合わせに対してSVCを訓練する\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # SVCを検証セットで評価\n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        # 良いスコアだったらスコアとパラメータを保持\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C':C, 'gamma':gamma}\n",
    "# 訓練セットと検証セットを用いてモデルを再構築し、\n",
    "#　テストセットで評価\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Best score on validation set:{:.2f}\".format(best_score))\n",
    "print(\"Best parameters:\",best_parameters)\n",
    "print(\"Test set score with best parameters:{:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "検証データに対する性能は0.96と先ほどより低くなっている。\n",
    "→　おそらく学習するデータ量が減ったため\n",
    "テストデータに対する性能は0.92とさらに低くなっている。\n",
    "→　新しいデータに対して主張できる性能は、単純なグリッドサーチで行った0.97ではなく、0.92である。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交差検証を用いたグリッドサーチ\n",
    "```\n",
    "上記で未知のデータに対して予測できるようになりました。しかし、汎化性を担保するためには分割時点で交差検証を用いる必要があります。データの分割方法によって性能が大きく変わるからです。交差検証に関しては以下を確認してください。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 処理フロー\n",
    "```\n",
    "1.split the data set trainval and test\n",
    "2.for list[gamma]\n",
    "3.for list[C]\n",
    "4.create the model\n",
    "5.get model score by cross validation\n",
    "6.if model score > model score[pre]\n",
    "7.save model score and params\n",
    "8.print best score and params\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "\n",
    "for gmma in [0.001,0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001,0.01,0.1,1,10,100]:\n",
    "        # それぞれのパラメータの組み合わせに対して\n",
    "        # SVCを訓練する\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        # 交差検証を行う\n",
    "        scores = cross_val_score(svm, X_trainval,y_trainval,cv=5)\n",
    "        # 交差検証の平均値を計算\n",
    "        score = np.mean(scores)\n",
    "        # 良いスコアであれbスコアとパラメータを記録\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C':C,'gamma':gamma}\n",
    "# 訓練セットと検証セットを合わせてモデルを再構築する\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "分割数は5なので、6*6*5=180通りのモデルを構築している。膨大な時間がかかるのが交差検証の問題点と言えます。交差検証はグリッドサーチのようなパラメータ探索手法と併用されることが多いため、交差検証を用いたグリッドサーチを指して交差検証と呼ぶことが多いです。scikit-learnはグリッドサーチを実装したクラス[GridSearchCV]を用意してくれています。\n",
    "実際に試してみたいと思います。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 処理フロー\n",
    "1.create params\n",
    "2.create the GridSearchCV instance\n",
    "3.split the data  train and test\n",
    "4.cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
      "test set score:0.97\n",
      "Best parameters:{'C': 100, 'gamma': 0.01}\n",
      "Best cross-validation score :0.97\n"
     ]
    }
   ],
   "source": [
    "# ライブラリ\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# パラメータ\n",
    "param_grid = {'C':[0.001, 0.01, 0.1, 1,10, 100],\n",
    "              'gamma':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))\n",
    "\n",
    "# GridSearch インスタンス生成\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "\n",
    "# パラメータの過剰適合を防ぐためにさらに訓練セットとテストセットを分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "\n",
    "# 交差検証を実行\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"test set score:{:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"Best parameters:{}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score :{:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "この方法だとパラメータの過剰適合が起こってしまうのでは？と思った方がいるかもしれません。\n",
    "重要なのはテストセットを使わなかったということです。グリッドサーチで見つけたパラメータはbest_params属性に、交差検証精度はbest_score属性に格納されています。\n",
    "注意しなけれいかないことは、各データが何を意味しているかです。\n",
    "\n",
    "grid_search.score(X_test, y_test))\n",
    "→　こちらは訓練セット全体を用いて訓練したモデルをテストデータで評価した精度です。\n",
    "\n",
    "grid_search.best_score_\n",
    "→　こちらは訓練セットに対する交差検証の平均交差懸賞精度です。\n",
    "\n",
    "なのでGridSearchCVで探索した最適なパラメータはgrid_search.best_params_にあり、モデルの汎化性能に関する評価精度はgrid_search.score(X_test, y_test)に格納されております。\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
