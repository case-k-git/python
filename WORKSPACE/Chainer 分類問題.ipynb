{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keisuke/.pyenv/versions/3.4.3/lib/python3.4/site-packages/chainer/_environment_check.py:38: UserWarning: Accelerate has been detected as a NumPy backend library.\n",
      "vecLib, which is a part of Accelerate, is known not to work correctly with Chainer.\n",
      "We recommend using other BLAS libraries such as OpenBLAS.\n",
      "For details of the issue, please see\n",
      "https://docs.chainer.org/en/stable/tips.html#mnist-example-does-not-converge-in-cpu-mode-on-mac-os-x.\n",
      "\n",
      "Also note that Chainer does not officially support Mac OS X.\n",
      "Please use it at your own risk.\n",
      "\n",
      "  ''')  # NOQA\n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer kesy：dict_keys(['DESCR', 'target_names', 'target', 'feature_names', 'data'])\n",
      "cancer target_names：['malignant' 'benign']\n",
      "cancer target：[0 1]\n",
      "cancer feasture_names：['area error' 'compactness error' 'concave points error' 'concavity error'\n",
      " 'fractal dimension error' 'mean area' 'mean compactness'\n",
      " 'mean concave points' 'mean concavity' 'mean fractal dimension'\n",
      " 'mean perimeter' 'mean radius' 'mean smoothness' 'mean symmetry'\n",
      " 'mean texture' 'perimeter error' 'radius error' 'smoothness error'\n",
      " 'symmetry error' 'texture error' 'worst area' 'worst compactness'\n",
      " 'worst concave points' 'worst concavity' 'worst fractal dimension'\n",
      " 'worst perimeter' 'worst radius' 'worst smoothness' 'worst symmetry'\n",
      " 'worst texture']\n",
      "cancer feasture_names shape：[30]\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(\"cancer kesy：{}\".format(cancer.keys()))\n",
    "print(\"cancer target_names：{}\".format(cancer.target_names))\n",
    "print(\"cancer target：{}\".format(np.unique(cancer.target)))\n",
    "print(\"cancer feasture_names：{}\".format(np.unique(cancer.feature_names)))\n",
    "print(\"cancer feasture_names shape：{}\".format(np.unique(cancer.feature_names.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_names(x):\n",
    "    if x == 0:\n",
    "        return \"malignant\"\n",
    "    if x == 1:\n",
    "        return \"benign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension      ...       worst perimeter  worst area  \\\n",
       "0                 0.07871      ...                184.60      2019.0   \n",
       "1                 0.05667      ...                158.80      1956.0   \n",
       "2                 0.05999      ...                152.50      1709.0   \n",
       "3                 0.09744      ...                 98.87       567.7   \n",
       "4                 0.05883      ...                152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  target_names  \n",
       "0          0.4601                  0.11890       0     malignant  \n",
       "1          0.2750                  0.08902       0     malignant  \n",
       "2          0.3613                  0.08758       0     malignant  \n",
       "3          0.6638                  0.17300       0     malignant  \n",
       "4          0.2364                  0.07678       0     malignant  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data = pd.DataFrame(columns=cancer['feature_names'],data = cancer['data'])\n",
    "cancer_data['target'] = cancer['target']\n",
    "cancer_data[\"target_names\"] = cancer_data['target'].apply(lambda x : get_target_names(x))\n",
    "cancer_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension      ...       worst perimeter  worst area  \\\n",
       "0                 0.07871      ...                184.60      2019.0   \n",
       "1                 0.05667      ...                158.80      1956.0   \n",
       "2                 0.05999      ...                152.50      1709.0   \n",
       "3                 0.09744      ...                 98.87       567.7   \n",
       "4                 0.05883      ...                152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  target_names  \n",
       "0          0.4601                  0.11890       0     malignant  \n",
       "1          0.2750                  0.08902       0     malignant  \n",
       "2          0.3613                  0.08758       0     malignant  \n",
       "3          0.6638                  0.17300       0     malignant  \n",
       "4          0.2364                  0.07678       0     malignant  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
       "       'target', 'target_names'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力変数と教師データ（出力変数）に切り分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教師データ\n",
    "t = cancer_data.iloc[:,-2]\n",
    "x = cancer_data.iloc[:,0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(t.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chainerで計算できるデータ形式に変換\n",
    "Chainerで計算を行うために、下記の３点を満たしているか確認を行っておきましょう。 こちらが指定された形式となっていない場合、学習の際にエラーが出てしまいます。\n",
    "```\n",
    "・入力変数や教師データがNumpyで定義されているか\n",
    "・分類の場合、ラベルが0から始まっているか\n",
    "・入力変数が float32、教師データが回帰の場合 float32、分類の場合 int32 で定義されているか\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type check:<class 'pandas.core.series.Series'>\n",
      "type check:<class 'pandas.core.frame.DataFrame'>\n",
      "label check:[0 1]\n",
      "dtype check:int64\n",
      "dtype check:float64\n"
     ]
    }
   ],
   "source": [
    "# ・分類の場合、ラベルが0から始まっているか\n",
    "print(\"type check:{}\".format(type(t)))\n",
    "print(\"type check:{}\".format(type(x)))\n",
    "print(\"label check:{}\".format(np.unique(t.values)))\n",
    "print(\"dtype check:{}\".format(t.dtype))\n",
    "print(\"dtype check:{}\".format(x.values.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "メモ：\n",
    "typeとdtypeがChainerで計算できるデータ形式に\n",
    "なっていないため変換する必要がありそうです。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x.astype('float32'))\n",
    "t = np.array(t.astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type check:<class 'numpy.ndarray'>\n",
      "type check:<class 'numpy.ndarray'>\n",
      "label check:[0 1]\n",
      "dtype check:int32\n",
      "dtype check:float32\n"
     ]
    }
   ],
   "source": [
    "print(\"type check:{}\".format(type(t)))\n",
    "print(\"type check:{}\".format(type(x)))\n",
    "print(\"label check:{}\".format(np.unique(t)))\n",
    "print(\"dtype check:{}\".format(t.dtype))\n",
    "print(\"dtype check:{}\".format(x.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "正しく型変換できていることが確認できます。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chainerで使用するデータセットの形式\n",
    "メモリに乗る程度の小規模なデータの場合は、入力変数と教師データをタプルで１セットにし、それをリスト化しておくことがChainer推奨の形式です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chainerで使用できるデータセットの形式\n",
    "dataset = list(zip(x, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教師データと検証データに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データのサンプル数\n",
    "n_train = int(len(dataset) * 0.7)\n",
    "\n",
    "# 訓練データ(train)と検証データ(test)に分割\n",
    "train, test = chainer.datasets.split_dataset_random(dataset, n_train, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.datasets.sub_dataset.SubDataset at 0x10b5ad9b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.datasets.sub_dataset.SubDataset at 0x10b666e80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークのモデルを定義\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(chainer.Chain):\n",
    "\n",
    "    # モデルの構造\n",
    "    def __init__(self, n_mid_units=5, n_out=2):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.fc1 = L.Linear(None, n_mid_units)  # 10 → None で自動推定\n",
    "            self.fc2 = L.Linear(None, n_out)  # 5 → None で自動推定\n",
    "\n",
    "    # 順伝播\n",
    "    def __call__(self, x):\n",
    "        u1 = self.fc1(x)\n",
    "        z1 = F.relu(u1)\n",
    "        u2 = self.fc2(z1)\n",
    "        return u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "# インスタンス化\n",
    "nn = NN()\n",
    "model = L.Classifier(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer\n",
    "```\n",
    "パラメータの更新を行います。\n",
    "Optimizerではパラメータの最適化を行うための最適化のアルゴリズムを選択します。 各最適化のアルゴリズムにはハイパーパラメータと呼ばれる定数を設定することもできますが、まだここでは触れず、後ほどしっかりと見ていきましょう\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = chainer.optimizers.SGD()  # 確率的勾配降下法（SGD）を使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 勾配降下法とは\n",
    "```\n",
    "確率的勾配降下法は傾きが0となる箇所を探索するために用いられます。\n",
    "以下の記事で損失関数を最小にすることが大切だと述べました。\n",
    "wでloss(w)を微分することでより傾きが小さくなる方にwを移動させます。\n",
    "このように損失をパラメタで微分して勾配を降る方向にパラメタを更新することを勾配降下法(GD)と言います。\n",
    "勾配降下法は以下の式で表現することができます。\n",
    "上記の方法を損失が減少しなくなるまで繰り返し行います。\n",
    "\n",
    "```\n",
    "### 確率的勾配降下法とは\n",
    "```\n",
    "全データではなく、ランダムに取り出したデータの一部(ミニバッチ)を使って損失を計算しパラメータ[w]を更新する方法です。Deep Learningでは一般に学習データが巨大なので確率的勾配法で学習が行われます。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.sgd.SGD at 0x10b7d87b8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratorの定義\n",
    "```\n",
    "ミニバッチの学習を行います。Iteratorでは「バッチサイズ」を決めることができます。\n",
    "順伝播で評価関数を計算するとき全てのサンプルを使用するのではなく、ミニバッチと呼ばれるサンプルの一部のデータセットのみで評価関数の計算を行い、逆伝播で勾配情報を計算し、最適化アルゴリズム（SGDやAdam等）によるパラメータの学習を行います。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### バッチサイズとは\n",
    "```\n",
    "バッチサイズとは？\n",
    "ランダムに抽出したサンプルの一部のデータセットのことです。\n",
    "100万レコードある場合、100万レコードいっぺんに実施することはメモリやCPUが足りません。\n",
    "なので100サンプルずつ実施するようにします。この1回の試行で利用するデータのサイズをバッチサイズといいます。\n",
    "またバッチサイズ1回行うことを1 epochといいます。\n",
    "100万レコードを、100サンプルずつ行う場合1万epochとなります。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter  = chainer.iterators.SerialIterator(test,  batchsize, repeat=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updaterでは、Optimizerの設定や使用するデバイス（CPUやGPU）の設定を行えます。\n",
    "\n",
    "CPUを使用する場合にはdevice=-1とオプションに指定しましょう。\n",
    "GPUを使用する場合にはdevice=0（GPUを複数枚指している場合はdevice=1なども存在）とオプションで明示しておきましょう。\n",
    "deviceを指定しない場合は、CPUが使用されます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = training.StandardUpdater(train_iter, optimizer, device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Trainerとextensionsの設定\n",
    "Trainerでは、エポック（ミニバッチを全て処理して１エポック）の回数や、そのextensionsでオプションを指定することにより、結果をログ出力や標準出力（インタラクティブに表示）できます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポックの数\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainerの宣言\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out='result/cancer')\n",
    "\n",
    "# 検証データで評価\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "\n",
    "# 学習の経過をtrainerのoutで指定したフォルダにlogというファイル名で記録する\n",
    "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
    "\n",
    "# １エポックごと（trigger）に、trainデータに対するlossと、testデータに対するloss、経過時間（elapsed_time）を標準出力させる\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J1           0.6175         0.65                      88.772      0.680788              0.107381      \n",
      "\u001b[J2           0.6325         0.65                      0.67837     0.67138               0.208196      \n",
      "\u001b[J3           0.6225         0.65                      0.674064    0.665612              0.305967      \n",
      "\u001b[J4           0.6275         0.65                      0.669229    0.661102              0.417129      \n",
      "\u001b[J5           0.623077       0.65                      0.66778     0.658048              0.515188      \n",
      "\u001b[J6           0.625          0.65                      0.665467    0.655788              0.625181      \n",
      "\u001b[J7           0.6275         0.65                      0.663342    0.653996              0.736354      \n",
      "\u001b[J8           0.6225         0.65                      0.664488    0.652914              0.844088      \n",
      "\u001b[J9           0.6275         0.65                      0.661933    0.651891              0.940649      \n",
      "\u001b[J10          0.625641       0.65                      0.662214    0.651171              1.04619       \n",
      "\u001b[J11          0.6225         0.65                      0.663408    0.650743              1.14479       \n",
      "\u001b[J12          0.6325         0.65                      0.658699    0.650103              1.24823       \n",
      "\u001b[J13          0.62           0.65                      0.664292    0.649989              1.34906       \n",
      "\u001b[J14          0.6275         0.65                      0.660784    0.64966               1.44493       \n",
      "\u001b[J15          0.625641       0.65                      0.661519    0.649495              1.54371       \n",
      "\u001b[J16          0.625          0.65                      0.66188     0.649362              1.66887       \n",
      "\u001b[J17          0.6275         0.65                      0.660663    0.649206              1.78745       \n",
      "\u001b[J18          0.6225         0.65                      0.663006    0.649181              1.91317       \n",
      "\u001b[J19          0.6275         0.65                      0.660586    0.64904               2.0212        \n",
      "\u001b[J20          0.625641       0.65                      0.661457    0.648978              2.13896       \n",
      "\u001b[J21          0.625          0.65                      0.661804    0.648949              2.2441        \n",
      "\u001b[J22          0.625          0.65                      0.661839    0.64891               2.34346       \n",
      "\u001b[J23          0.625          0.65                      0.66176     0.648889              2.44549       \n",
      "\u001b[J24          0.6325         0.65                      0.657936    0.648707              2.54164       \n",
      "\u001b[J25          0.620513       0.65                      0.664054    0.648825              2.64183       \n",
      "\u001b[J26          0.625          0.65                      0.661748    0.648786              2.75962       \n",
      "\u001b[J27          0.625          0.65                      0.661774    0.648785              2.8736        \n",
      "\u001b[J28          0.625          0.65                      0.66176     0.648758              2.99883       \n",
      "\u001b[J29          0.6275         0.65                      0.660477    0.648702              3.12869       \n",
      "\u001b[J30          0.625641       0.65                      0.661424    0.648689              3.24503       \n",
      "\u001b[J31          0.625          0.65                      0.661746    0.648733              3.36706       \n",
      "\u001b[J32          0.63           0.65                      0.659263    0.648602              3.48781       \n",
      "\u001b[J33          0.625          0.65                      0.661796    0.648629              3.60869       \n",
      "\u001b[J34          0.625          0.65                      0.661905    0.648642              3.72969       \n",
      "\u001b[J35          0.623077       0.65                      0.662753    0.648712              3.84867       \n",
      "\u001b[J36          0.6275         0.65                      0.660501    0.648629              3.96901       \n",
      "\u001b[J37          0.6275         0.65                      0.660561    0.64862               4.08751       \n",
      "\u001b[J38          0.6225         0.65                      0.663116    0.648702              4.20418       \n",
      "\u001b[J39          0.6275         0.65                      0.660412    0.648682              4.32445       \n",
      "\u001b[J40          0.623077       0.65                      0.662728    0.648721              4.4376        \n",
      "\u001b[J41          0.6275         0.65                      0.660508    0.648672              4.53551       \n",
      "\u001b[J42          0.6275         0.65                      0.660436    0.648632              4.63841       \n",
      "\u001b[J43          0.6225         0.65                      0.663081    0.648717              4.73316       \n",
      "\u001b[J44          0.625          0.65                      0.661807    0.648746              4.83661       \n",
      "\u001b[J45          0.625641       0.65                      0.661457    0.648763              4.93511       \n",
      "\u001b[J46          0.6225         0.65                      0.663108    0.648775              5.03779       \n",
      "\u001b[J47          0.6325         0.65                      0.657887    0.648645              5.14421       \n",
      "\u001b[J48          0.62           0.65                      0.664368    0.648756              5.26615       \n",
      "\u001b[J49          0.63           0.65                      0.659189    0.648648              5.37246       \n",
      "\u001b[J50          0.623077       0.65                      0.662835    0.648671              5.46994       \n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の確認\n",
    "最後に今回のモデルでの予測結果を確認しておきましょう。 Trainerを使用すると、result/wineというフォルダができ、この中にlogというファイルが自動的に生成されます。 こちらに、学習結果が全て保存されており、後で学習の状況を可視化して確認したりできます。\n",
    "\n",
    "まずは、logのファイルをPythonで読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logファイルから結果の読み込み\n",
    "with open('result/cancer/log') as f:\n",
    "    logs = json.load(f)\n",
    "    results = pd.DataFrame(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>main/accuracy</th>\n",
       "      <th>main/loss</th>\n",
       "      <th>validation/main/accuracy</th>\n",
       "      <th>validation/main/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107381</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>88.772014</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.680788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.208196</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.678370</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.671380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.305967</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.674064</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.665612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.417129</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.669229</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.661102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.515188</td>\n",
       "      <td>5</td>\n",
       "      <td>199</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.667780</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.658048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.625181</td>\n",
       "      <td>6</td>\n",
       "      <td>239</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.665467</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.655788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.736354</td>\n",
       "      <td>7</td>\n",
       "      <td>279</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.663342</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.653996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.844088</td>\n",
       "      <td>8</td>\n",
       "      <td>319</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.664488</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.652914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.940649</td>\n",
       "      <td>9</td>\n",
       "      <td>359</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.661933</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.651891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.046190</td>\n",
       "      <td>10</td>\n",
       "      <td>398</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.662214</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.651171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.144795</td>\n",
       "      <td>11</td>\n",
       "      <td>438</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.663408</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.650743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.248231</td>\n",
       "      <td>12</td>\n",
       "      <td>478</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.658699</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.650103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.349058</td>\n",
       "      <td>13</td>\n",
       "      <td>518</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.664292</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.649989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.444929</td>\n",
       "      <td>14</td>\n",
       "      <td>558</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660784</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.649660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.543712</td>\n",
       "      <td>15</td>\n",
       "      <td>597</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.661519</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.649495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.668871</td>\n",
       "      <td>16</td>\n",
       "      <td>637</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661880</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.649362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.787452</td>\n",
       "      <td>17</td>\n",
       "      <td>677</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660663</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.649206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.913173</td>\n",
       "      <td>18</td>\n",
       "      <td>717</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.663006</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.649181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.021200</td>\n",
       "      <td>19</td>\n",
       "      <td>757</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660586</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.649040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.138958</td>\n",
       "      <td>20</td>\n",
       "      <td>796</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.661457</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.244097</td>\n",
       "      <td>21</td>\n",
       "      <td>836</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661804</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.343455</td>\n",
       "      <td>22</td>\n",
       "      <td>876</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661839</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.445489</td>\n",
       "      <td>23</td>\n",
       "      <td>916</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661760</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.541641</td>\n",
       "      <td>24</td>\n",
       "      <td>956</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.657936</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.641831</td>\n",
       "      <td>25</td>\n",
       "      <td>995</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.664054</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.759624</td>\n",
       "      <td>26</td>\n",
       "      <td>1035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661748</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.873602</td>\n",
       "      <td>27</td>\n",
       "      <td>1075</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661774</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.998827</td>\n",
       "      <td>28</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661760</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.128691</td>\n",
       "      <td>29</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660477</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.245025</td>\n",
       "      <td>30</td>\n",
       "      <td>1194</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.661424</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.367064</td>\n",
       "      <td>31</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661746</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.487814</td>\n",
       "      <td>32</td>\n",
       "      <td>1274</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.659263</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.608686</td>\n",
       "      <td>33</td>\n",
       "      <td>1314</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661796</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.729692</td>\n",
       "      <td>34</td>\n",
       "      <td>1354</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.848674</td>\n",
       "      <td>35</td>\n",
       "      <td>1393</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.969011</td>\n",
       "      <td>36</td>\n",
       "      <td>1433</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660501</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.087509</td>\n",
       "      <td>37</td>\n",
       "      <td>1473</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660561</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.204183</td>\n",
       "      <td>38</td>\n",
       "      <td>1513</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.663116</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.324446</td>\n",
       "      <td>39</td>\n",
       "      <td>1553</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660412</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.437600</td>\n",
       "      <td>40</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.662728</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.535515</td>\n",
       "      <td>41</td>\n",
       "      <td>1632</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660508</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.638405</td>\n",
       "      <td>42</td>\n",
       "      <td>1672</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.660436</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.733163</td>\n",
       "      <td>43</td>\n",
       "      <td>1712</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.663081</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.836608</td>\n",
       "      <td>44</td>\n",
       "      <td>1752</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661807</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4.935105</td>\n",
       "      <td>45</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.661457</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.037793</td>\n",
       "      <td>46</td>\n",
       "      <td>1831</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.663108</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.144211</td>\n",
       "      <td>47</td>\n",
       "      <td>1871</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.657887</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.266147</td>\n",
       "      <td>48</td>\n",
       "      <td>1911</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.664368</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.372462</td>\n",
       "      <td>49</td>\n",
       "      <td>1951</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.659189</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.469943</td>\n",
       "      <td>50</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.662835</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.648671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elapsed_time  epoch  iteration  main/accuracy  main/loss  \\\n",
       "0       0.107381      1         40       0.617500  88.772014   \n",
       "1       0.208196      2         80       0.632500   0.678370   \n",
       "2       0.305967      3        120       0.622500   0.674064   \n",
       "3       0.417129      4        160       0.627500   0.669229   \n",
       "4       0.515188      5        199       0.623077   0.667780   \n",
       "5       0.625181      6        239       0.625000   0.665467   \n",
       "6       0.736354      7        279       0.627500   0.663342   \n",
       "7       0.844088      8        319       0.622500   0.664488   \n",
       "8       0.940649      9        359       0.627500   0.661933   \n",
       "9       1.046190     10        398       0.625641   0.662214   \n",
       "10      1.144795     11        438       0.622500   0.663408   \n",
       "11      1.248231     12        478       0.632500   0.658699   \n",
       "12      1.349058     13        518       0.620000   0.664292   \n",
       "13      1.444929     14        558       0.627500   0.660784   \n",
       "14      1.543712     15        597       0.625641   0.661519   \n",
       "15      1.668871     16        637       0.625000   0.661880   \n",
       "16      1.787452     17        677       0.627500   0.660663   \n",
       "17      1.913173     18        717       0.622500   0.663006   \n",
       "18      2.021200     19        757       0.627500   0.660586   \n",
       "19      2.138958     20        796       0.625641   0.661457   \n",
       "20      2.244097     21        836       0.625000   0.661804   \n",
       "21      2.343455     22        876       0.625000   0.661839   \n",
       "22      2.445489     23        916       0.625000   0.661760   \n",
       "23      2.541641     24        956       0.632500   0.657936   \n",
       "24      2.641831     25        995       0.620513   0.664054   \n",
       "25      2.759624     26       1035       0.625000   0.661748   \n",
       "26      2.873602     27       1075       0.625000   0.661774   \n",
       "27      2.998827     28       1115       0.625000   0.661760   \n",
       "28      3.128691     29       1155       0.627500   0.660477   \n",
       "29      3.245025     30       1194       0.625641   0.661424   \n",
       "30      3.367064     31       1234       0.625000   0.661746   \n",
       "31      3.487814     32       1274       0.630000   0.659263   \n",
       "32      3.608686     33       1314       0.625000   0.661796   \n",
       "33      3.729692     34       1354       0.625000   0.661905   \n",
       "34      3.848674     35       1393       0.623077   0.662753   \n",
       "35      3.969011     36       1433       0.627500   0.660501   \n",
       "36      4.087509     37       1473       0.627500   0.660561   \n",
       "37      4.204183     38       1513       0.622500   0.663116   \n",
       "38      4.324446     39       1553       0.627500   0.660412   \n",
       "39      4.437600     40       1592       0.623077   0.662728   \n",
       "40      4.535515     41       1632       0.627500   0.660508   \n",
       "41      4.638405     42       1672       0.627500   0.660436   \n",
       "42      4.733163     43       1712       0.622500   0.663081   \n",
       "43      4.836608     44       1752       0.625000   0.661807   \n",
       "44      4.935105     45       1791       0.625641   0.661457   \n",
       "45      5.037793     46       1831       0.622500   0.663108   \n",
       "46      5.144211     47       1871       0.632500   0.657887   \n",
       "47      5.266147     48       1911       0.620000   0.664368   \n",
       "48      5.372462     49       1951       0.630000   0.659189   \n",
       "49      5.469943     50       1990       0.623077   0.662835   \n",
       "\n",
       "    validation/main/accuracy  validation/main/loss  \n",
       "0                       0.65              0.680788  \n",
       "1                       0.65              0.671380  \n",
       "2                       0.65              0.665612  \n",
       "3                       0.65              0.661102  \n",
       "4                       0.65              0.658048  \n",
       "5                       0.65              0.655788  \n",
       "6                       0.65              0.653996  \n",
       "7                       0.65              0.652914  \n",
       "8                       0.65              0.651891  \n",
       "9                       0.65              0.651171  \n",
       "10                      0.65              0.650743  \n",
       "11                      0.65              0.650103  \n",
       "12                      0.65              0.649989  \n",
       "13                      0.65              0.649660  \n",
       "14                      0.65              0.649495  \n",
       "15                      0.65              0.649362  \n",
       "16                      0.65              0.649206  \n",
       "17                      0.65              0.649181  \n",
       "18                      0.65              0.649040  \n",
       "19                      0.65              0.648978  \n",
       "20                      0.65              0.648949  \n",
       "21                      0.65              0.648910  \n",
       "22                      0.65              0.648889  \n",
       "23                      0.65              0.648707  \n",
       "24                      0.65              0.648825  \n",
       "25                      0.65              0.648786  \n",
       "26                      0.65              0.648785  \n",
       "27                      0.65              0.648758  \n",
       "28                      0.65              0.648702  \n",
       "29                      0.65              0.648689  \n",
       "30                      0.65              0.648733  \n",
       "31                      0.65              0.648602  \n",
       "32                      0.65              0.648629  \n",
       "33                      0.65              0.648642  \n",
       "34                      0.65              0.648712  \n",
       "35                      0.65              0.648629  \n",
       "36                      0.65              0.648620  \n",
       "37                      0.65              0.648702  \n",
       "38                      0.65              0.648682  \n",
       "39                      0.65              0.648721  \n",
       "40                      0.65              0.648672  \n",
       "41                      0.65              0.648632  \n",
       "42                      0.65              0.648717  \n",
       "43                      0.65              0.648746  \n",
       "44                      0.65              0.648763  \n",
       "45                      0.65              0.648775  \n",
       "46                      0.65              0.648645  \n",
       "47                      0.65              0.648756  \n",
       "48                      0.65              0.648648  \n",
       "49                      0.65              0.648671  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果の確認\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10b7e1b70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD7CAYAAACIYvgKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b6660b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy（精度）を表示\n",
    "results[['main/accuracy', 'validation/main/accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "精度は訓練データに対しては62%ほどであり、\n",
    "検証データに対して65%ほどであることが分かります。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10b8bc710>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIf4fy8WlDV5O84QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b8e8588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss（損失関数）を表示\n",
    "results[['main/loss', 'validation/main/loss']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度を上げるために"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手っ取り早く精度を上げることが出来る方法として、BatchNormalizationが挙げられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(chainer.Chain):\n",
    "\n",
    "    # モデルの構造\n",
    "    def __init__(self, n_mid_units=5, n_out=3):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.fc1 = L.Linear(None, n_mid_units)\n",
    "            self.fc2 = L.Linear(None, n_out)\n",
    "            self.bn = L.BatchNormalization(10)  # Batch Normalizationは平均と分散がパラメータ\n",
    "\n",
    "    # 順伝播\n",
    "    def __call__(self, x):\n",
    "        h = self.bn(x)  # Batch Normalizationの処理を追加\n",
    "        h = self.fc1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを固定\n",
    "np.random.seed(1)\n",
    "\n",
    "# モデルのインスタンス化\n",
    "nn = NN()\n",
    "model = L.Classifier(nn)\n",
    "\n",
    "# Optimizerの定義\n",
    "optimizer = chainer.optimizers.SGD()\n",
    "optimizer.setup(model)  # modelと紐付ける\n",
    "\n",
    "# Iteratorの定義\n",
    "batchsize = 10\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)\n",
    "\n",
    "# Updaterの定義\n",
    "updater = chainer.training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "\n",
    "# trainerとそのextensionsの設定\n",
    "epoch = 50\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out='result/wine')\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の実行\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
